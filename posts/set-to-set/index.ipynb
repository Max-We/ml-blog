{
 "cells": [
  {
   "cell_type": "raw",
   "id": "233bc02a-2d9b-4339-8cd4-13db54bc6a9f",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Set-to-Set: An extension of the Seq-to-Seq paradigm using attention\"\n",
    "description: \"Not all data is sequential. How can neural networks be applied to non-sequential data like sets, when the Seq-to-Seq paradigm fails?\"\n",
    "author:\n",
    "    - \"Maximilian Weichart\"\n",
    "    - \"Noah Meißner\"\n",
    "date: \"10/06/2024\"\n",
    "image: images/set-to-set.png\n",
    "bibliography: references.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add6e46-c5a0-4ecd-a988-d369a7f883a1",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Sequence-to-sequence (Seq-to-Seq) models are a common solution for tasks with a natural sequential structure, such as translating sentences into another language [@sutskever-2014]. These models are particularly useful because they can handle variable-length inputs and outputs. But what happens when the underlying task has no order?\n",
    "\n",
    "Sorting a set of numbers is a good example, which we explore in this article. Here, a Seq-to-Seq model would not work optimally because the order of the numbers in the input data could affect the result [@vinyals-2015A]. This highlights the limitations of Seq-to-Seq when it comes to processing sets rather than sequences.\n",
    "\n",
    "In the following sections, we will explore how to develop an architecture that can handle such Set-to-Set tasks. The implementations presented are based on theory from several scientific papers, including concepts such as attention [@graves-2014], pointer networks [@vinyals-2015B], and the Read-Process-Write architecture [@vinyals-2015A].\n",
    "\n",
    "## Setup\n",
    "\n",
    "::: {.callout-note}\n",
    "In order to understand the following content, we assume basic knowledge of neural networks, backpropagation and Seq-to-Seq models. We will rely on the PyTorch library for the implementation. We have provided further literature for each approach. This can be used both to deepen your knowledge and to go deeper into a topic if you are having difficulty understanding it.\n",
    ":::\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "As a benchmark for the models in this experiment, we will conduct a number-sorting experiment similar to @vinyals-2015A on arrays with a length $s$ (controlled by a hyperparameter) containing numbers normalized to $[-1;1]$. The network will receive an unordered array $x$ and has to learn to output an ordered array $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f8726c-852a-4d88-a520-f1dec359a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410888f9-5d8e-4560-9d64-47f3cf1a624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Hyperparameters\n",
    "# Dataset\n",
    "SEQ_LENGTH = 5\n",
    "NUM_SAMPLES = 2000\n",
    "\n",
    "# Model\n",
    "ITEM_SIZE = 1\n",
    "EMBEDDING_SIZE = 32\n",
    "HIDDEN_SIZE = 32\n",
    "BATCH_SIZE = 256\n",
    "PROCESS_STEPS = 5 # RPW model\n",
    "\n",
    "# Training\n",
    "LR = 0.01\n",
    "N_EPOCHS = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834b0421-ae90-44b5-90b1-615b0c59c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitSortDataset(Dataset):\n",
    "    def __init__(self, num_samples, seq_length):\n",
    "        self.num_samples = num_samples\n",
    "        self.seq_length = seq_length\n",
    "        self.data = self.generate_data()\n",
    "\n",
    "    def generate_data(self):\n",
    "        data = []\n",
    "        for _ in range(self.num_samples):\n",
    "            sequence = [random.random() for _ in range(self.seq_length)]\n",
    "            unsorted = torch.tensor(sequence, dtype=torch.float32)\n",
    "            sorted_seq = torch.sort(unsorted)[0]\n",
    "            data.append((unsorted, sorted_seq))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c729c263-ac10-4e93-8b2b-f4e02f07a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Dataloader creation\n",
    "# Create the datasets\n",
    "train_val_dataset = DigitSortDataset(num_samples=NUM_SAMPLES, seq_length=SEQ_LENGTH)\n",
    "\n",
    "# Split the train_val_dataset\n",
    "train_size = int(0.8 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    train_val_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f456046-5b3e-48f5-9bf7-f8e069da3daf",
   "metadata": {},
   "source": [
    "For the rest of this article, we will be using arrays with $s=5$, but the reader can adjust this value in the Jupyter Notebook. An example for a training pair $(x,y)$ from the data loader looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049f16f0-6006-4a3d-8100-e68e183c776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example x: tensor([0.8946, 0.3203, 0.5510, 0.4022, 0.6636])\n",
      "Example y: tensor([0.3203, 0.4022, 0.5510, 0.6636, 0.8946])\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "example_x, example_y = train_dataset[0]\n",
    "print(\"Example x:\", example_x)\n",
    "print(\"Example y:\", example_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b1946-0eed-49fa-884d-648697d11a9a",
   "metadata": {},
   "source": [
    "### Training functions\n",
    "\n",
    "As a final step for the setup, we will define a few functions which will be used to train and evaluate the models in the next few sections. You can ignore these functions for now, but if you're interested in how they work, you can unfold the code-blok below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a7bff6-fe53-475a-a454-38d1c5e97395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: Training, \n",
    "def train(model, dataloader, use_cross_entropy):\n",
    "    criterion = nn.CrossEntropyLoss() if use_cross_entropy else nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            unsorted, sorted_seq = batch\n",
    "\n",
    "            prediction = model(unsorted)\n",
    "\n",
    "            if use_cross_entropy: # cross entropy if target are indices\n",
    "                _, indices = torch.sort(unsorted, dim=-1)\n",
    "                target = torch.argsort(indices, dim=-1)\n",
    "            else: # MSE if target are values\n",
    "                target = sorted_seq\n",
    "\n",
    "            loss = criterion(prediction, target)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    final_loss = total_loss / len(dataloader)\n",
    "    return model, final_loss\n",
    "\n",
    "def probs_to_x(probabilities, unsorted_sequence):\n",
    "    indices = torch.argmax(probabilities, dim=-1)  # Shape: [255, 5]\n",
    "    batch_size, seq_len = unsorted_sequence.shape\n",
    "    batch_indices = torch.arange(batch_size).unsqueeze(1).expand(-1, seq_len)\n",
    "    return unsorted_sequence[batch_indices, indices]  # Shape: [255, 5]\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    n = 0\n",
    "    n_right = 0\n",
    "    total_divergence = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            unsorted, sorted_seq = batch\n",
    "\n",
    "            output = model(unsorted)\n",
    "            if len(output.shape) == 3:\n",
    "                prediction = probs_to_x(output, unsorted)\n",
    "            else:\n",
    "                prediction = output\n",
    "\n",
    "            total_divergence += (sorted_seq - prediction).abs().sum().item()\n",
    "            n_right += (sorted_seq == prediction).sum().item()\n",
    "            n += sorted_seq.size(0) * sorted_seq.size(1)\n",
    "\n",
    "    accuracy = f\"{((n_right / n) * 100):.2f}%\"\n",
    "    avg_divergence = total_divergence / n\n",
    "    return accuracy, avg_divergence\n",
    "\n",
    "def report_training_results(model_name, accuracy, divergence, embedding_size=EMBEDDING_SIZE):\n",
    "    \"\"\"Function report training results and hyperparameters in a table\"\"\"\n",
    "    data = {\n",
    "        'Metric': ['Model', 'Embedding Size', 'Sequence Length', 'Training Epochs', 'Accuracy', 'Avg. Divergence'],\n",
    "        'Value': [model_name, embedding_size, SEQ_LENGTH, N_EPOCHS, accuracy, divergence]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def inspect(model, dataloader, is_pointer_network):\n",
    "    \"\"\"Function to look at model predictions / target values directly\"\"\"\n",
    "    model.eval()\n",
    "    batch = next(iter(dataloader))\n",
    "    unsorted, sorted_seq = batch\n",
    "    prediction = model(unsorted)\n",
    "    if is_pointer_network:\n",
    "        prediction = probs_to_x(prediction, unsorted)\n",
    "\n",
    "    results = [\n",
    "        {\n",
    "            'Example Nr.': i,\n",
    "            'Type': t,\n",
    "            'Values': ','.join(f'{x:.4f}' for x in seq[i].tolist())\n",
    "        }\n",
    "        for i in [0, 5, 10]\n",
    "        for t, seq in zip(['input', 'prediction', 'target'], [unsorted, prediction, sorted_seq])\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def visualize_divergence(df):\n",
    "    unique_examples = df['Example Nr.'].unique()\n",
    "    example_index = unique_examples[0]\n",
    "    df_example = df[df['Example Nr.']==example_index]\n",
    "    arr_input = np.array([float(value) for value in df_example[df_example['Type'] == 'input']['Values'].values[0].split(',')])\n",
    "    arr_prediction = np.array([float(value) for value in df_example[df_example['Type'] == 'prediction']['Values'].values[0].split(',')])\n",
    "    arr_target = np.array([float(value) for value in df_example[df_example['Type'] == 'target']['Values'].values[0].split(',')])\n",
    "\n",
    "    arr_divergence = arr_prediction - arr_target\n",
    "    indices = np.arange(len(arr_divergence))\n",
    "\n",
    "    bar_width = 0.95  \n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    bars = ax.bar(indices, arr_divergence, bar_width, color='royalblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Index in Array', fontsize=12)\n",
    "    ax.set_ylabel('Divergence', fontsize=12)\n",
    "    ax.set_title('Divergence per Index'.format(example_index), fontsize=13)\n",
    "    ax.legend(['Divergence'], loc='upper right')\n",
    "    \n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    ax.set_ylim(min(arr_divergence) - 1, max(arr_divergence) + 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c98e7f-994f-467f-bc8a-16ad6f2954da",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Now we will introduce potential solutions to Set-to-Set problem^[In our case of sorting numbers, it would be more accurate to call it a Set-to-Seq problem, but we'll use \"Set-to-Set\" in this articles to emphasize the non-sequential data.] introduced earlier.\n",
    "\n",
    "### Feed-Forward Network {#sec-ff}\n",
    "As a baseline model, we will implement a feed-forward network with input- and output dimensions $s$, which is one of the simplest types of neural networks [@bebis-1994]. The structure of the network consists of a single linear layer followed by a `LeakyReLU` activation function. We are using `LeakyReLU` because the input values can be positive and negative.\n",
    "\n",
    "::: {.callout-tip}\n",
    "#### Further Reading\n",
    "- [Deep Learning Basics — Part 7 — Feed Forward Neural Networks (FFNN)- medium](https://medium.com/@sasirekharameshkumar/deep-learning-basics-part-10-feed-forward-neural-networks-ffnn-93a708f84a31)\n",
    "- [Feedforward neural network - geeksforgeeks](https://www.geeksforgeeks.org/feedforward-neural-network/)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c358060-4187-4f7c-910b-ced4fbc0f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFF(nn.Module):\n",
    "    def __init__(self, s):\n",
    "        super().__init__()\n",
    "        self.l = nn.Linear(s, s, bias=False)\n",
    "        self.a = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.a(self.l(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa82e1-dc85-4314-b61a-caa93a04d382",
   "metadata": {},
   "source": [
    "Training this model achieves the following results on our evaluation-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b474c6a-067b-4a3b-b594-72486e838c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model</td>\n",
       "      <td>Feed-Forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Embedding Size</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequence Length</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training Epochs</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avg. Divergence</td>\n",
       "      <td>0.095851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric         Value\n",
       "0            Model  Feed-Forward\n",
       "1   Embedding Size          None\n",
       "2  Sequence Length             5\n",
       "3  Training Epochs           250\n",
       "4         Accuracy         0.00%\n",
       "5  Avg. Divergence      0.095851"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-ff\n",
    "#| tbl-cap: Training & evaluation metrics for the feed-forward model\n",
    "#| echo: false\n",
    "model = LinearFF(SEQ_LENGTH)\n",
    "model, final_loss = train(model, train_loader, use_cross_entropy=False)\n",
    "accuracy, divergence = evaluate(model, val_loader)\n",
    "report_ff = report_training_results(\"Feed-Forward\", accuracy, divergence, None)\n",
    "report_ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b4bcd-d9af-4de6-8259-e25d6ef197b3",
   "metadata": {},
   "source": [
    "The evaluation of our model shows an accuracy score of 0%, mainly because the model struggles to predict `Float32` values with full accuracy. As the accuracy metric alone doesn't fully capture the model's performance, we also calculated the average divergence as a complementary measure. This statistic reflects the positive or negative deviation of the model output from its corresponding target value at each index in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13e22872-e6da-4992-b347-f3b9af032054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: fig-inspect-ff\n",
    "#| fig-cap: Concrete predictions and training pairs for the feed-forward model\n",
    "#| echo: false\n",
    "df = inspect(model, val_loader, False)\n",
    "visualize_divergence(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bf1ad-1961-4885-9bb3-b731132ffe79",
   "metadata": {},
   "source": [
    "Additionally, we will inspect a few samples from the evaluation set, combined with the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d873bacd-d54c-4b8d-b1a3-047650448938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Example Nr.</th>\n",
       "      <th>Type</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>input</td>\n",
       "      <td>0.0850,0.4038,0.4878,0.6103,0.6019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.1571,0.3136,0.4480,0.5758,0.6981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>0.0850,0.4038,0.4878,0.6019,0.6103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>input</td>\n",
       "      <td>0.5476,0.8797,0.8482,0.5416,0.5308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.2360,0.4701,0.6863,0.8853,1.0755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>target</td>\n",
       "      <td>0.5308,0.5416,0.5476,0.8482,0.8797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>input</td>\n",
       "      <td>0.9732,0.6948,0.5976,0.8599,0.2902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.2506,0.4770,0.7003,0.8977,1.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>target</td>\n",
       "      <td>0.2902,0.5976,0.6948,0.8599,0.9732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Example Nr.        Type                              Values\n",
       "0            0       input  0.0850,0.4038,0.4878,0.6103,0.6019\n",
       "1            0  prediction  0.1571,0.3136,0.4480,0.5758,0.6981\n",
       "2            0      target  0.0850,0.4038,0.4878,0.6019,0.6103\n",
       "3            5       input  0.5476,0.8797,0.8482,0.5416,0.5308\n",
       "4            5  prediction  0.2360,0.4701,0.6863,0.8853,1.0755\n",
       "5            5      target  0.5308,0.5416,0.5476,0.8482,0.8797\n",
       "6           10       input  0.9732,0.6948,0.5976,0.8599,0.2902\n",
       "7           10  prediction  0.2506,0.4770,0.7003,0.8977,1.0958\n",
       "8           10      target  0.2902,0.5976,0.6948,0.8599,0.9732"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db865c-4661-4256-b267-8781d3751509",
   "metadata": {},
   "source": [
    "We can observe that the model seems to make reasonable predictions, but they are imprecise and often include made-up values which are not present in the input-array.\n",
    "\n",
    "Based on the evaluation, we noticed two further disadvantages of the model architecture in addition to performance:  \n",
    "\n",
    "- **Fixed input and output size (problem 1):** The model works with a fixed size $s$ for both inputs and outputs. This limits flexibility and makes it difficult to deal with varying data sets.  \n",
    "- **Simultaneous processing of all inputs (problem 2):** All inputs are used simultaneously to generate all outputs. However, in the case of sorting arrays, the output of a value and the previous values are dependent on each other. This also has the effect that an input value can appear several times in the output of the *FF-network* instead of just once.\n",
    "\n",
    "These limitations contribute to the suboptimal performance of the model and highlight the need to revise the architecture to improve efficiency and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab17b5-f566-4ac0-85b8-02a3a3faeb3a",
   "metadata": {},
   "source": [
    "### Seq-to-Seq {#sec-s2s}\n",
    "\n",
    "To find a solution to these problems, we have defined a Seq-to-Seq model using a recurrent architecture with an LSTM [@hochreiter-1997]. It generates outputs *autoregressive*, meaning that the previous outputs from the model are used to produce the next output. Additionally, this autoregressive nature also allows us to process variable-sized inputs, eliminating both of the problems that the baseline feed-forward architecture in the previous section has.\n",
    "\n",
    "::: {.callout-tip}\n",
    "#### Further Reading\n",
    "- [What is LSTM? Introduction to Long Short-Term Memory - medium](https://medium.com/@rebeen.jaff/what-is-lstm-introduction-to-long-short-term-memory-66bd3855b9ce)\n",
    "- [What is LSTM – Long Short Term Memory? - geeksforgeeks](https://www.geeksforgeeks.org/deep-learning-introduction-to-long-short-term-memory/)\n",
    ":::\n",
    "\n",
    "The Seq-to-Seq architecture, consisting of encoder and decoder, is visualized in @fig-s2s\n",
    "\n",
    "![Seq-to-Seq architecture](images/s2s.png){#fig-s2s}\n",
    "\n",
    "Before we can generate outputs,  the model must analyze the entire input. This is why we use an *encoder*, which processes the entire input sequence $x$ and then passes the hidden state $e$ to the decoder as context. The *decoder* receives the context $e$ from the encoder and uses it to generate the output $y$ in an *autoregressive* manner.\n",
    "\n",
    "Based on this architecture, we now define the model architecture in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aea0003-cb48-4ab0-b772-f6e3d4f637a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLstm(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLstm, self).__init__()\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, xs, h, c, s):\n",
    "        hs = []\n",
    "        for t in range(s):\n",
    "            xt = xs[:, t, :] # <1>\n",
    "            h, c = self.lstm_cell(xt, (h, c))\n",
    "            hs.append(h)\n",
    "\n",
    "        return torch.stack(hs, dim=1), (h, c)\n",
    "\n",
    "\n",
    "class DecoderLstm(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DecoderLstm, self).__init__()\n",
    "\n",
    "        # Variables\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "\n",
    "        # Output\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Sigmoid()  # find out why this helps?\n",
    "        )\n",
    "\n",
    "    def forward(self, xs, h, c, s):\n",
    "        ys = []\n",
    "        yt = torch.zeros((xs.shape[0], self.output_size))  # SOS\n",
    "\n",
    "        for t in range(s):\n",
    "            h, c = self.lstm_cell(yt, (h, c)) #<2>\n",
    "\n",
    "            yt = self.fc(h) # <3>\n",
    "            ys.append(yt)\n",
    "\n",
    "        return torch.stack(ys, dim=1).squeeze(-1)\n",
    "        \n",
    "\n",
    "class SeqToSeq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(SeqToSeq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = xs.unsqueeze(-1)\n",
    "        b, s = xs.size()[0], xs.size()[1]\n",
    "        h, c = torch.zeros(b, self.encoder.hidden_size), torch.zeros(b, self.encoder.hidden_size)\n",
    "\n",
    "        hs, (h, c) = self.encoder(xs, h, c, s)\n",
    "        return self.decoder(hs, h, c, s) # <4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ea43a-86d9-48dc-ae8e-5b5306207400",
   "metadata": {},
   "source": [
    "1. **Read in data:** First, all input values are read in one after the other (sequentially)\n",
    "2. **Autoregressive output generation:** The decoder generates it's next hidden state by feeding previous outputs back into the LSTM\n",
    "3. **LSTM Output Layer:** The LSTM output is projected to a final output $y$ using a linear layer\n",
    "4. **Initialize Decoder:** The outputs (hidden states) and final hidden state from the encoder are used to initialize the decoder\n",
    "\n",
    "Afterward, we will use this architecture to train a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a035d4b-c82e-4582-b70d-e24741f66d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Embedding Size</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequence Length</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training Epochs</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avg. Divergence</td>\n",
       "      <td>0.025922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric     Value\n",
       "0            Model      LSTM\n",
       "1   Embedding Size      None\n",
       "2  Sequence Length         5\n",
       "3  Training Epochs       250\n",
       "4         Accuracy     0.00%\n",
       "5  Avg. Divergence  0.025922"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-s2s\n",
    "#| tbl-cap: Training & evaluation metrics for the Seq-to-Seq model\n",
    "#| echo: false\n",
    "model = SeqToSeq(\n",
    "    EncoderLstm(input_size=ITEM_SIZE, hidden_size=HIDDEN_SIZE),\n",
    "    DecoderLstm(input_size=ITEM_SIZE, hidden_size=HIDDEN_SIZE, output_size=ITEM_SIZE),\n",
    ")\n",
    "model, final_loss = train(model, train_loader, use_cross_entropy=False)\n",
    "accuracy, divergence = evaluate(model, val_loader)\n",
    "report_s2s = report_training_results(\"LSTM\", accuracy, divergence, None)\n",
    "report_s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d667de97-c955-4b51-bbd8-2c7ec3d34932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo: false\n",
    "# inspect(model, val_loader, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c2524-251e-49b2-8cba-cffa96061231",
   "metadata": {},
   "source": [
    "Looking at the evaluation results, we observe an accuracy score of 0%, indicating that the precision problem of the Feed-Forward network (see @sec-ff) has not yet been resolved. However, the average divergence is improving, suggesting the Seq-to-Seq architecture had a positive effect on the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33605737-5628-4ec8-b467-41a88c140e82",
   "metadata": {},
   "source": [
    "### Seq-to-Seq with Embeddings {#sec-embedding}\n",
    "\n",
    "To improve the accuracy of the model, a logical next step would is to improve the input encoding via embeddings, instead of using the values as direct input to the model. Typically, an embedding layer can be implemented by a simple linear layer without bias and without an activation function.\n",
    "\n",
    "\n",
    "::: {.callout-tip}\n",
    "#### Further Reading\n",
    "- [What are Embeddings and how do it work? - medium](https://medium.com/@eugenesh4work/what-are-embeddings-and-how-do-it-work-b35af573b59e)\n",
    "- [What Is Embedding and What Can You Do with It - towardsdatascience](https://www.geeksforgeeks.org/deep-learning-introduction-to-long-short-term-memory/)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7742371-ca50-4b3e-83f8-183da3c70030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(1, embedding_size, bias=False)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        return self.lin(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62590f3-820a-4069-aa36-2727f338c224",
   "metadata": {},
   "source": [
    "To use this `Embedder` module in the previously defined `Seq-to-Seq` module, we will integrate it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d67cf52-725d-491d-a9bf-93dbd4b4dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqToSeq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embedder=None):\n",
    "        super(SeqToSeq, self).__init__()\n",
    "        self.embedder = embedder\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = xs.unsqueeze(-1)\n",
    "        b, s = xs.size()[0], xs.size()[1]\n",
    "        h, c = torch.zeros(b, self.encoder.hidden_size), torch.zeros(b, self.encoder.hidden_size)\n",
    "\n",
    "        es = self.embedder(xs) if self.embedder else xs # <1>\n",
    "        hs, (h, c) = self.encoder(es, h, c, s) # <2>\n",
    "        return self.decoder(hs, h, c, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f6ab4-3ab4-4caa-bd44-2aae1cc7db2f",
   "metadata": {},
   "source": [
    "1. **Embedding generation:** Each of the elements from the input sequence are converted to embeddings\n",
    "2. **Input to the encoder:** The embeddings are passed to the encoder (instead of the original input sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56399d97-69dc-4e8a-ade0-57aede4c8c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model</td>\n",
       "      <td>LSTM + Embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Embedding Size</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequence Length</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training Epochs</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avg. Divergence</td>\n",
       "      <td>0.015684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric              Value\n",
       "0            Model  LSTM + Embeddings\n",
       "1   Embedding Size                 32\n",
       "2  Sequence Length                  5\n",
       "3  Training Epochs                250\n",
       "4         Accuracy              0.00%\n",
       "5  Avg. Divergence           0.015684"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-embedding\n",
    "#| tbl-cap: Training & evaluation metrics for the embedding Seq-to-Seq model\n",
    "#| echo: false\n",
    "SeqToSeq(\n",
    "    EncoderLstm(input_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE),\n",
    "    DecoderLstm(input_size=ITEM_SIZE, hidden_size=HIDDEN_SIZE, output_size=ITEM_SIZE),\n",
    "    Embedder(embedding_size=EMBEDDING_SIZE)\n",
    ")\n",
    "model, final_loss = train(model, train_loader, use_cross_entropy=False)\n",
    "accuracy, divergence = evaluate(model, val_loader)\n",
    "report_embedding = report_training_results(\"LSTM + Embeddings\", accuracy, divergence, EMBEDDING_SIZE)\n",
    "report_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c550e6-77c1-4c37-bf76-c4372240dd38",
   "metadata": {},
   "source": [
    "By using embeddings, we can observe a continuous decrease in the average divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e552e3d-70a8-4674-90e2-bd6cb3a70b38",
   "metadata": {},
   "source": [
    "### Seq-to-Seq with Attention {#sec-attention}\n",
    "\n",
    "Although the average divergence is improving, it is still not optimal. A common problem of Seq-to-Seq models is, that the hidden state of the encoder-LSTM can become a bottleneck for the entire model [@vinyals-2015A].\n",
    "\n",
    "This problem can be addressed using an attention-mechanism [@graves-2014], where we not only pass the hidden state $h$ and the cell state $c$ to the decoder, but also include additional information from the original input sequence. This allows the decoder to analyze and weight the input sequences again before making predictions for the outputs.\n",
    "\n",
    "#### How does the attention mechanism work?\n",
    "\n",
    "Foremost, we would like to emphasize that there are different types of attentional mechanisms [@graves-2014]. In this article, we will only focus on content based, specifically additive attention. For those interested in exploring other types of attention, additional resources are provided below.\n",
    "\n",
    "::: {.callout-tip}\n",
    "##### Further Reading\n",
    "- [Attention and Self-Attention for NLP - slds-lmu](https://slds-lmu.github.io/seminar_nlp_ss20/attention-and-self-attention-for-nlp.html)\n",
    "- [Attention in transformers, visually explained | Chapter 6, Deep Learning - 3Blue1Brown](https://www.youtube.com/watch?v=eMlx5fFNoYc)\n",
    ":::\n",
    "\n",
    "\n",
    "The following diagram displays how content-based attention is integrated in the encoder-decoder architecture.\n",
    "\n",
    "![Encoder-decoder architecture with content-based attention](images/content-attention.png){#fig-attention}\n",
    "\n",
    "To understand what's going on, we will first introduce the basics of content-based attention. Here, we will re-use the following variables from @fig-s2s:\n",
    "\n",
    "- $d$: decoder hidden state\n",
    "- $e$: encoder hidden state\n",
    "- $o$: encoder outputs\n",
    "\n",
    "Content-based attention as defined by @vinyals-2015B consists of three steps^[We use the same notation as in the paper here, with slight modifications]: First, we calculate a similarity-score $u$ between the encoder outputs $o$ and the decoder hidden states $d$. Each of these scores indicates the relevance of a specific encoder output to the current decoder state.\n",
    "\n",
    "$$\n",
    "u_j = v^T \\tanh(W_1 o_j + W_2 d)  \n",
    "$${#eq-u}\n",
    "\n",
    "In a second step, the softmax-function is applied to the attention-score, resulting in the attentions-weights $a$.\n",
    "\n",
    "$$a_j = \\operatorname{softmax}(u_j)$${#eq-a}\n",
    "\n",
    "Finally, a context is calculated using the attention-weights $a$ and the encoder outputs $o$.\n",
    "\n",
    "$$d' = \\sum_{j=1}^n a_j o_j$${#eq-c}\n",
    "\n",
    "By summing these values, we obtain our new hidden state $d'$ for the decoder, which has now been enhanced with additional knowledge about the input sequence.\n",
    "\n",
    "\n",
    "Going back to @fig-attention, @eq-u is displayed in red, @eq-a in orange and @eq-c in blue. We can see that without attention (grey colors), the decoder would be limited to the information provided in the encoder hidden state $e$. But by using attention, the decoder can include information about the entire input sequence by comparing its own hidden state $d$ to the encoder outputs $o$ at each step while generating outputs. This should mitigate the bottleneck problem discussed in earlier sections (see @sec-s2s).\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "We will now proceed by implementing the attention-mechanism in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43fa929a-f38a-411e-959c-51aa98a8d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        self.w1 = nn.Linear(key_size, query_size, bias=False)\n",
    "        self.w2 = nn.Linear(query_size, query_size, bias=False)\n",
    "        self.v = nn.Linear(query_size, 1, bias=False)\n",
    "        self.compress = nn.Sequential(\n",
    "            nn.Linear(query_size * 2, query_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, key, query, create_context, compress_context=False):\n",
    "        u = self.v(torch.tanh(self.w1(key) + self.w2(query).unsqueeze(1))).squeeze(-1) # <1>\n",
    "        a = F.softmax(u, dim=1) # <2>\n",
    "        if create_context:\n",
    "            r = torch.bmm(a.unsqueeze(1), key).squeeze(1) # <3>\n",
    "            concat = torch.cat([query, r], dim=1)\n",
    "            context = self.compress(concat) if compress_context else concat\n",
    "            return context\n",
    "        else:\n",
    "            return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f54de4-b4c8-4247-93fb-cefd6b16fcb6",
   "metadata": {},
   "source": [
    "1. Calculate the similarity-score $u$ (see @eq-u)\n",
    "2. Calculate the attention-weights $a$ via softmax on $u$ (see @eq-a)\n",
    "3. \"Combine\" all the information into a single context, which will be used as the next decoder hidden state $d'$ (see @eq-c)\n",
    "\n",
    "::: {.callout-note}\n",
    "Please ignore the `concat` and `compress` steps for now. These are used in the Read-Process-Write architecture introduced in the following sections.\n",
    ":::\n",
    "\n",
    "Finally, we will integrate the attention module into the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53bc0cea-095c-4ce2-be66-bb457df52950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLstm(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, use_attention):\n",
    "        super(DecoderLstm, self).__init__()\n",
    "\n",
    "        # Variables\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "\n",
    "        # Attention\n",
    "        self.attention = AdditiveAttention(hidden_size, hidden_size) if use_attention else None # <1>\n",
    "\n",
    "        # Output\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Sigmoid()  # find out why this helps?\n",
    "        )\n",
    "\n",
    "    def forward(self, xs, h, c, s):\n",
    "        ys = []\n",
    "        yt = torch.zeros((xs.shape[0], self.output_size))  # SOS\n",
    "\n",
    "        for t in range(s):\n",
    "            h, c = self.lstm_cell(yt, (h, c))\n",
    "\n",
    "            if self.attention:\n",
    "                context = self.attention(xs, h, create_context=True, compress_context=True) # <2>\n",
    "                yt = self.fc(context)\n",
    "            else:\n",
    "                yt = self.fc(h)\n",
    "            ys.append(yt)\n",
    "\n",
    "        return torch.stack(ys, dim=1).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64272ecf-db08-44e4-b5ff-a50d032c045a",
   "metadata": {},
   "source": [
    "1. Initialize the attention module\n",
    "2. Apply attention\n",
    "\n",
    "Using this architecture, we will now train and evaluate an attention-based Seq-to-Seq model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "872b95c6-3893-4223-ad9f-23f7f35783d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model</td>\n",
       "      <td>LSTM + Embeddings + Attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Embedding Size</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequence Length</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training Epochs</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avg. Divergence</td>\n",
       "      <td>0.010806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric                          Value\n",
       "0            Model  LSTM + Embeddings + Attention\n",
       "1   Embedding Size                             32\n",
       "2  Sequence Length                              5\n",
       "3  Training Epochs                            250\n",
       "4         Accuracy                          0.00%\n",
       "5  Avg. Divergence                       0.010806"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-attention\n",
    "#| tbl-cap: Training & evaluation metrics for the content-attention based Seq-to-Seq model\n",
    "#| echo: false\n",
    "model = SeqToSeq(\n",
    "    EncoderLstm(input_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE),\n",
    "    DecoderLstm(input_size=ITEM_SIZE, hidden_size=HIDDEN_SIZE, output_size=ITEM_SIZE, use_attention=True),\n",
    "    Embedder(embedding_size=EMBEDDING_SIZE)\n",
    ")\n",
    "model, final_loss = train(model, train_loader, use_cross_entropy=False)\n",
    "accuracy, divergence = evaluate(model, val_loader)\n",
    "report_attn = report_training_results(\"LSTM + Embeddings + Attention\", accuracy, divergence, EMBEDDING_SIZE)\n",
    "report_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f395d9b-9fd2-4c7f-8453-ba1d0b8b0958",
   "metadata": {},
   "source": [
    "We can observe that the addition of the attention mechanism significantly reduces the average divergence, which indicates that the bottleneck-problem of the hidden state is being alleviated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434c4d1-365c-4ae1-a42f-f1fe390ce473",
   "metadata": {},
   "source": [
    "### Seq-to-Seq with Pointers {#sec-pointer}\n",
    "\n",
    "As previously outlined, the issue of the hidden state bottleneck was addressed through the introduction of attention. Nevertheless, this does not address the issue of precision (see @sec-ff): The problem arises because the network attempts to predict values in the ordered array directly, however because these are `Float32` values, it is highly unlikely that the network will be able to output it in full precision.\n",
    "\n",
    "To address this issue, we can modify the model to predict indices of the ordered array, instead of values: This means that we will train a model that understands how to rank items without needing to predict exact output values, thereby resolving the precision problem. This idea is known as a pointer network [@vinyals-2015B] and we will implement it in this section.\n",
    "\n",
    "::: {.callout-tip}\n",
    "#### Further Reading\n",
    "- [Pointer networks : What are they? - medium](https://kierszbaumsamuel.medium.com/pointer-networks-what-are-they-c3cb68fae076)\n",
    "- [The Power of Pointer Networks - hyperscience](https://www.hyperscience.com/blog/the-power-of-pointer-networks/)\n",
    ":::\n",
    "\n",
    "Implementing a pointer network is actually a simplified model of the content-based attention Seq-to-Seq model from @sec-attention. The diagram below displays the Seq-to-Seq architecture using a pointer network as a decoder.\n",
    "\n",
    "![ Encoder-decoder architecture with a pointer net](images/ptr-attention.png){#fig-ptr}\n",
    "\n",
    "The pointer network is essentially content-based attention, but without calculating a context (@eq-c) and instead using the attention-weights (see @eq-a) as outputs. These attention-weights are a distribution over the input-vocabulary and can therefore serve as \"pointers\" to the input vocabulary. To use this distribution as a hidden-state for subsequent steps, we simply do a matrix multiplication with this distribution to convert it into a scalar-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c72c031-5562-489a-a996-99047be7c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPointerLstm(nn.Module):\n",
    "    def __init__(self, hidden_size, use_attention):\n",
    "        super(DecoderPointerLstm, self).__init__()\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm_cell = nn.LSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "        # Attention\n",
    "        self.attention = AdditiveAttention(hidden_size, hidden_size) if use_attention else None\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, xs, h, c, s):\n",
    "        ys = []\n",
    "        yt = torch.zeros((xs.shape[0], self.hidden_size))  # SOS\n",
    "\n",
    "        for t in range(s):\n",
    "            h, c = self.lstm_cell(yt, (h, c))\n",
    "\n",
    "            # now returns a softmax distribution\n",
    "            p = self.attention(xs, h, create_context=False) # <1>\n",
    "            ys.append(p)\n",
    "\n",
    "            # compile next input\n",
    "            # this could also be just the pointer distribution, but would restrict\n",
    "            # the model to a specific sequence length (not generalizable) so we compile\n",
    "            # a new state from it\n",
    "            yt = torch.bmm(p.unsqueeze(1), xs).squeeze(1) # <2>\n",
    "\n",
    "        return torch.stack(ys, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48258e23-66d0-4c31-a4ba-ef7401b4841f",
   "metadata": {},
   "source": [
    "1. **No Context Vector Creation:** Directly return the attention-weights which serve as pointers to the input-vocabulary\n",
    "2. **Compress softmax distribution:** Calculate a scalar value to serve as the next hidden state for the decoder\n",
    "\n",
    "Using this new architecture, we will train and evaluate a pointer-net based Seq-to-Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e709476d-3801-46e2-a7b8-74f2db014458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model</td>\n",
       "      <td>LSTM + Embeddings + Attention + Pointer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Embedding Size</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequence Length</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training Epochs</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>93.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avg. Divergence</td>\n",
       "      <td>0.00228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric                                    Value\n",
       "0            Model  LSTM + Embeddings + Attention + Pointer\n",
       "1   Embedding Size                                       32\n",
       "2  Sequence Length                                        5\n",
       "3  Training Epochs                                      250\n",
       "4         Accuracy                                   93.05%\n",
       "5  Avg. Divergence                                  0.00228"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-ptr\n",
    "#| tbl-cap: Training & evaluation metrics for the pointer Seq-to-Seq model\n",
    "#| echo: false\n",
    "model = SeqToSeq(\n",
    "    EncoderLstm(input_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE),\n",
    "    DecoderPointerLstm(hidden_size=HIDDEN_SIZE, use_attention=True),\n",
    "    Embedder(embedding_size=EMBEDDING_SIZE)\n",
    ")\n",
    "model, final_loss = train(model, train_loader, use_cross_entropy=True)\n",
    "accuracy, divergence = evaluate(model, val_loader)\n",
    "report_ptr = report_training_results(\"LSTM + Embeddings + Attention + Pointer\", accuracy, divergence, EMBEDDING_SIZE)\n",
    "report_ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca4cf47-547e-411a-9dd6-54dcffbcc184",
   "metadata": {},
   "source": [
    "The results improve significantly with the addition of the pointer mechanism: Not only is the accuracy metric working, indicating that we have solved the precision problem, but also the average divergence is decreasing as a side effect of the model predicting more precise values.\n",
    "\n",
    "Comparing the model output with the target values directly (see @tbl-inspect-ptr), it is difficult to find wrong outputs due to the high accuracy. However, we can observe that when the model makes a mistake, the resulting value is still guaranteed to be present in the input array, due to the pointer mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fab0ae3-aaf9-46ad-ba9d-36f1522b67b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Example Nr.</th>\n",
       "      <th>Type</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>input</td>\n",
       "      <td>0.0850,0.4038,0.4878,0.6103,0.6019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.0850,0.4038,0.4878,0.6019,0.6103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>0.0850,0.4038,0.4878,0.6019,0.6103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>input</td>\n",
       "      <td>0.5476,0.8797,0.8482,0.5416,0.5308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.5416,0.5476,0.5476,0.8482,0.8797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>target</td>\n",
       "      <td>0.5308,0.5416,0.5476,0.8482,0.8797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>input</td>\n",
       "      <td>0.9732,0.6948,0.5976,0.8599,0.2902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>prediction</td>\n",
       "      <td>0.2902,0.5976,0.6948,0.8599,0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>target</td>\n",
       "      <td>0.2902,0.5976,0.6948,0.8599,0.9732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Example Nr.        Type                              Values\n",
       "0            0       input  0.0850,0.4038,0.4878,0.6103,0.6019\n",
       "1            0  prediction  0.0850,0.4038,0.4878,0.6019,0.6103\n",
       "2            0      target  0.0850,0.4038,0.4878,0.6019,0.6103\n",
       "3            5       input  0.5476,0.8797,0.8482,0.5416,0.5308\n",
       "4            5  prediction  0.5416,0.5476,0.5476,0.8482,0.8797\n",
       "5            5      target  0.5308,0.5416,0.5476,0.8482,0.8797\n",
       "6           10       input  0.9732,0.6948,0.5976,0.8599,0.2902\n",
       "7           10  prediction  0.2902,0.5976,0.6948,0.8599,0.9732\n",
       "8           10      target  0.2902,0.5976,0.6948,0.8599,0.9732"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-inspect-ptr\n",
    "#| tbl-cap: Concrete predictions and training pairs for the pointer Seq-to-Seq model\n",
    "#| echo: false\n",
    "df = inspect(model, val_loader, True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e584a7-23f1-469e-aa97-96e68ca8a35e",
   "metadata": {},
   "source": [
    "### Read-Process-Write Architecture {#sec-rpw}\n",
    "\n",
    "The Seq-to-Seq architecture combined with a pointer network already achieves good results. However, there is an important observation to be made: The Seq-to-Seq architecture is reading the inputs sequentially and generating outputs sequentially (see @fig-s2s). As a result, the order in which the input array is presented has an effect on the performance of the model because it changes the encoding. This property can be advantageous when dealing with sequential data, but not for Set2Set. Sets, by definition lack order and thus every set should be encoded identically (see @vinyals-2015A). \n",
    "\n",
    "Read-Process-Write Architecture, introduced by @vinyals-2015A addresses this problem by using an *order invariant encoding* via content-based attention in the encoder and a *glimpse* mechanism in the decoder for *order invariant decoding*.\n",
    "\n",
    "Compared to the previous sections, we will now continue with the notation from @vinyals-2015A with slight modifications so that the reader can easily compare our implementation to the paper.\n",
    "\n",
    "- $m$: Memory vector (previously embeddings)\n",
    "- $q$: Hidden state of the LSTM (previously $h$)\n",
    "- $q^*$: Concatenation of the hidden State of the LSTM + attention readout: $[q, r]$\n",
    "\n",
    "@fig-rpw displays the Read-Process-Write architecture, excluding the glimpse mechanism, which will be described in a following section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d68f37-4523-44c4-8b6b-24b92c325780",
   "metadata": {},
   "source": [
    "![Read-Process-Write architecture (simplified without glimpse-mechanism)](images/rpw.png){#fig-rpw .ligthbox}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044bc72e-1fa3-4920-8456-bdc789218642",
   "metadata": {},
   "source": [
    "Although this diagram is more verbose than @fig-s2s, in essence the Read-Process-Write architecture can be understood as an Encoder-Decoder model with embeddings. In fact, in our implementation, we use the same embedder introduced in @sec-embedding for this model. The encoder is called the *Process* block and the main difference to the Seq-toSeq encoder from @fig-s2s is, that it can \"see\" the input sequence $m$ only via an attention mechanism, instead of as input into the LSTM, resulting in an *order invariant encoding*. As a side effect, we can now also specify how many process steps we want to take, potentially even more than the sequence length $s$ of the input array ^[In our implementation we're using 5 processing steps, but these can be adjusted as seen fit]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df9081df-a6a0-4289-b4d8-bd56e8109b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessEncoderLstm(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ProcessEncoderLstm, self).__init__()\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm_cell = nn.LSTMCell(hidden_size * 2, hidden_size)\n",
    "\n",
    "        # Attention\n",
    "        self.attention = AdditiveAttention(key_size=input_size, query_size=hidden_size)\n",
    "\n",
    "    def forward(self, ms, q_star, h, c, process_steps):\n",
    "        for t in range(process_steps): # <1>\n",
    "            q, c = self.lstm_cell(q_star, (h, c)) # <2>\n",
    "\n",
    "            q_star = self.attention(ms, q, create_context=True) # <3>\n",
    "\n",
    "        return q_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5d79a-30c6-4ddb-93bd-634c31fd7bf4",
   "metadata": {},
   "source": [
    "1. **Independent lengths:** The encoding is not dependent on the length of the input sequence anymore. This gives more flexibility and the potential to define the number of processing steps manually.\n",
    "2. **Input Modification:** Instead of feeding the inputs $m$ sequentially into the encoder LSTM, we're using $q^*$ as the input\n",
    "3. **$q^*$ generation**: Concatenation of the previous hidden state $q$ and the attention readout from comparing the memory vector $m$ with $q$\n",
    "\n",
    "As shown in @fig-rpw, $q^*$ from the *Process* block is used to initialize the *Write* block. The *Write* block is mostly identical to the decoder pointer-network introduced in @sec-pointer, with the addition of a glimpse-mechanism, which was also introduced by @vinyals-2015A. Glimpse is another content-based attention module which is calculated from $q^*$ and the memory vector $m$. The glimpse-value $g$ is then passed as input $x$ and $q^*$  as the hidden state $h$ to the LSTM. Although the authors only briefly describe the design-decision behind this mechanism, it increases the performance of the model significantly. While the decoder in the Seq-to-Seq architecture was able to rely on its previous outputs as inputs $x$ for the following steps, in a non-sequential setting as in Set-to-Set, this is not the case, and the glimpse value $g$ serves as a non-sequential replacement for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50f21ae7-70e2-4d5c-a18e-a1b2968e1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriteDecoderPointerLstm(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(WriteDecoderPointerLstm, self).__init__()\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Attention\n",
    "        self.attention = AdditiveAttention(key_size=input_size, query_size=hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Glimpse\n",
    "        self.glimpse = AdditiveAttention(key_size=input_size, query_size=input_size) # <1>\n",
    "        self.glimpse_projection = nn.Linear(hidden_size, input_size) # <2>\n",
    "\n",
    "    def forward(self, m, h, c, s):\n",
    "        ys = []\n",
    "\n",
    "        for t in range(s):\n",
    "            # glimpse\n",
    "            # h = q_star (from process-block)\n",
    "            g = self.glimpse(m, self.glimpse_projection(h), create_context=True, compress_context=True) # <3>\n",
    "\n",
    "            h, c = self.lstm_cell(g, (h, c))\n",
    "\n",
    "            # returns softmax\n",
    "            y = self.attention(m, h, create_context=False)\n",
    "            ys.append(y)\n",
    "\n",
    "        return torch.stack(ys, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654aec5c-c500-40d4-94ae-1bb5b33970a9",
   "metadata": {},
   "source": [
    "1. **Initialize glimpse:** Glimpse is just another attention module\n",
    "2. **Initialize a projection layer:** This makes the shapes of the hidden state $q^*$ and memory vector $m$ compatible\n",
    "3. **Apply glimpse:** Before generating a new hidden state, calculate the glimpse value $g$ to use as the input $x$ for the LSTM\n",
    "\n",
    "To combine the *Read*, *Process* and *Write* modules into a single model, we will introduce the `RPW` class using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00a32db0-f3d3-4419-9c1d-a52b7171450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.module = ProcessEncoderLstm(input_size=input_size, hidden_size=hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, ms, s):\n",
    "        bs = ms.size(0)\n",
    "        q_star = torch.zeros(bs, self.hidden_size * 2)\n",
    "        h = torch.zeros(bs, self.hidden_size)\n",
    "        c = torch.zeros(bs, self.hidden_size)\n",
    "\n",
    "        return self.module(ms, q_star, h, c, s)\n",
    "\n",
    "\n",
    "class WriteBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.module = WriteDecoderPointerLstm(input_size=input_size, hidden_size=hidden_size * 2)\n",
    "\n",
    "    def forward(self, m, q_star):\n",
    "        bs, s = m.size(0), m.size(1)\n",
    "        c = torch.zeros(bs, self.module.hidden_size)\n",
    "\n",
    "        return self.module(m, q_star, c, s)\n",
    "\n",
    "\n",
    "class RPW(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, process_steps):\n",
    "        super().__init__()\n",
    "        self.read = Embedder(embedding_size=embedding_size)\n",
    "        self.process = ProcessBlock(input_size=embedding_size, hidden_size=hidden_size)\n",
    "        self.write = WriteBlock(input_size=embedding_size, hidden_size=hidden_size)\n",
    "        self.process_steps = process_steps\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = xs.unsqueeze(-1)\n",
    "        m = self.read(xs)\n",
    "        q_star = self.process(m, self.process_steps) # <1>\n",
    "        pointers = self.write(m, q_star) # <2>\n",
    "\n",
    "        return pointers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8311b-46b6-4736-9d2c-61a01cb9fd60",
   "metadata": {},
   "source": [
    "1. Generates a hidden state $q^*$ which is used to initialize to *Write* module. This encoding is order invariant.\n",
    "2. Generates the pointer distribution using the newly added glimpse mechanism\n",
    "\n",
    "Finally, we will train and evaluate a new model with this architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c225dc5-a758-4d1a-981c-b2c3b30d8709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model</td>\n",
       "      <td>Read-Process-Write (Pointer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Embedding Size</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequence Length</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training Epochs</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>98.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avg. Divergence</td>\n",
       "      <td>0.00036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric                         Value\n",
       "0            Model  Read-Process-Write (Pointer)\n",
       "1   Embedding Size                            32\n",
       "2  Sequence Length                             5\n",
       "3  Training Epochs                           250\n",
       "4         Accuracy                        98.70%\n",
       "5  Avg. Divergence                       0.00036"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-rpw\n",
    "#| tbl-cap: Training & evaluation metrics for the Read-Process-Write architecture\n",
    "#| echo: false\n",
    "model = RPW(EMBEDDING_SIZE, HIDDEN_SIZE, PROCESS_STEPS)\n",
    "model, final_loss = train(model, train_loader, use_cross_entropy=True)\n",
    "accuracy, divergence = evaluate(model, val_loader)\n",
    "report_rpw = report_training_results(\"Read-Process-Write (Pointer)\", accuracy, divergence, EMBEDDING_SIZE)\n",
    "report_rpw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c4bf315-0ca8-437e-8541-73390ad7dbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: fig-inspect-rpw\n",
    "#| fig-cap: Concrete predictions and training pairs for the Read-Process-Write model\n",
    "#| echo: false\n",
    "df = inspect(model, val_loader, True)\n",
    "visualize_divergence(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7629a-140b-4880-b092-30afc4267629",
   "metadata": {},
   "source": [
    "The results show almost perfect accuracy values and a very low divergence. This indicates that the order invariant encoding / decoding, which is implemented via content-based attention, improves the performance. With more processing steps and longer training time, this performance can be improved even further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939283d-fe67-42e3-bf49-54f3549b5f8f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The Seq-to-Seq architecture is useful for processing sequential data of varying lengths, but faces challenges when dealing with unordered inputs or outputs. In this article, we highlight the strengths of the Read-Process-Write architecture, which is an extension of the classical Seq-to-Seq paradigm to a Set-to-Set paradigm, by building the final model from the ground up and comparing the performance improvements at each step. LSTMs are better at handling variable-length sequences than a baseline feed-forward networks (see @sec-ff), and can be combined into a Seq-to-Seq model with an encoder and decoder (see @sec-s2s), potentially also using embeddings for improved performance (see @sec-embedding). Incorporating an attention-mechanism can help to overcome the hidden-state bottleneck, significantly improving performance (see @sec-attention). The introduction of pointer networks, on the other hand, allows the model to be more accurate in its output, by predicting indices from the input vocabulary rather than the values directly (see @sec-pointer). Finally, by processing the inputs for the encoder and decoder LSTM in a non-sequential manner via attention, the Read-Process-Write architecture (see @sec-rpw) eliminates the sequential limitation of Seq-to-Seq models and results in a Set-to-Set architecture, which may be used to solve the problem of sorting numbers introduced in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1b77e-55dd-4fdc-83d1-8a404f09bcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
